{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## **Sequence-to-sequence learning : EN to FR translation** - revision 01\n",
    "## **Using pre-trained models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **1. Small_vocab translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_data(path):\n",
    "\n",
    "    # Nombre maximum de lignes à renvoyer\n",
    "    max_lines = 140000\n",
    "    \n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\",  encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    # On convertit les majuscules en minulcule\n",
    "    data = data.lower()\n",
    "    \n",
    "    data = data.split('\\n')\n",
    "    return data[:min(len(data),max_lines)]\n",
    "\n",
    "#Chargement des textes dans les 2 langues (max lignes = max_lines)\n",
    "txt_en = load_data('../data/small_vocab_en')\n",
    "txt_fr = load_data('../data/small_vocab_fr')\n",
    "\n",
    "text_pairs = []\n",
    "for line in range(len(txt_en)):\n",
    "    txt_fr[line]=txt_fr[line].replace('à', 'a')\n",
    "    text_pairs.append((txt_en[line], \"[start] \" + txt_fr[line] + \" [end]\" ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('california is sometimes warm during december , and it is never mild in march .', '[start] californie est parfois chaud en décembre , et il est doux jamais en mars . [end]')\n",
      "('china is beautiful during july , and it is never quiet in march .', '[start] chine est belle en juillet , et il est jamais tranquille en mars . [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Vectorizing the English and French text pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "def load_vocab(file_path):\n",
    "    with open(file_path, \"r\",  encoding=\"utf-8\") as file:\n",
    "        return file.read().split('\\n')[:-1]\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 30\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    vocabulary = load_vocab(\"../data/eng_vocab.txt\"),\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    # standardize=custom_standardization,\n",
    "    vocabulary = load_vocab(\"../data/fra_vocab.txt\"),\n",
    ")\n",
    "english_texts = [pair[0] for pair in text_pairs]\n",
    "french_texts = [pair[1] for pair in text_pairs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Sample sentences for translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sentence=[]\n",
    "for i in range(20):\n",
    "    input_sentence.append(random.choice(english_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **2. Sequence-to-sequence learning with RNNs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading of the trained RNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq2seq_rnn = keras.models.load_model(\"../data/seq2seq_rnn-fra-en-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seq2seq_rnn.load_weights(\"../data/seq2seq_rnn-fra-en-model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src =  <HDF5 file \"seq2seq_rnn-fra-en-model.weights.h5\" (mode r)>\n",
      "group =  bidirectional\n",
      "group =  dense\n",
      "group =  dropout\n",
      "group =  embedding\n",
      "group =  embedding_1\n",
      "group =  english\n",
      "group =  french\n",
      "group =  gru_1\n",
      "group =  top_level_model_weights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "\n",
    "def split(fname_src: str, fname_dest_prefix: str, maxsize_per_file: float):\n",
    "    \"\"\"\n",
    "    Splits an `h5` file into smaller parts, size of each not exceeding\n",
    "    `maxsize_per_file`.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    dest_fnames = []\n",
    "    is_file_open = False\n",
    "    \n",
    "    with h5py.File(fname_src, \"r\") as src:\n",
    "        print(\"src = \",src)\n",
    "        for group in src:\n",
    "            print(\"group = \",group)\n",
    "            fname = f\"{fname_dest_prefix}{idx}.h5\"\n",
    "            \n",
    "            if not is_file_open:\n",
    "                dest = h5py.File(fname, \"w\")\n",
    "                dest.attrs.update(src.attrs)\n",
    "                dest_fnames.append(fname)\n",
    "                is_file_open = True\n",
    "                \n",
    "            group_id = dest.require_group(src[group].parent.name)\n",
    "            src.copy(f\"/{group}\", group_id, name=group)\n",
    "            \n",
    "            if os.path.getsize(fname) > maxsize_per_file:\n",
    "                dest.close()\n",
    "                idx += 1\n",
    "                is_file_open = False            \n",
    "        dest.close()\n",
    "\n",
    "    return dest_fnames\n",
    "    \n",
    "\n",
    "def combine(fname_in: list, fname_out: str):\n",
    "    \"\"\"\n",
    "    Combines a series of `h5` files into a single file.\n",
    "    \"\"\"\n",
    "    with h5py.File(fname_out, \"w\") as combined:\n",
    "        for fname in fname_in:\n",
    "            with h5py.File(fname, \"r\") as src:\n",
    "                combined.attrs.update(src.attrs)\n",
    "                for group in src:\n",
    "                    group_id = combined.require_group(src[group].parent.name)\n",
    "                    src.copy(f\"/{group}\", group_id, name=group)\n",
    "                    \n",
    "                    \n",
    "\n",
    "prefix = \"../data/seq2seq_rnn-fra-en-model2_part\"\n",
    "fname_src = \"../data/seq2seq_rnn-fra-en-model.weights.h5\"\n",
    "size_max = 90 * 1024**2  # maximum size allowed in bytes\n",
    "fname_parts = split(fname_src, fname_dest_prefix=prefix, maxsize_per_file=size_max)\n",
    "combine(fname_in=fname_parts, fname_out=\"../data/seq2seq_rnn-fra-en-model2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our RNN encoder and decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "EN   india is beautiful during october , and it is quiet in fall .\n",
      "FR-> l inde est beau en octobre et il est calme a l automne\n",
      "-\n",
      "EN   india is pleasant during fall , but it is never beautiful in winter .\n",
      "FR-> l inde est agréable a lautomne mais il est beau jamais en hiver\n",
      "-\n",
      "EN   the united states is snowy during january , and it is never chilly in autumn .\n",
      "FR-> les étatsunis est la neige en janvier et il est jamais froid a l automne\n",
      "-\n",
      "EN   new jersey is usually beautiful during april , but it is dry in may .\n",
      "FR-> new jersey est généralement beau en avril mais il est sec en mai\n",
      "-\n",
      "EN   he dislikes bananas , grapes , and strawberries .\n",
      "FR-> il naime les bananes les raisins et les fraises\n",
      "-\n",
      "EN   our least favorite fruit is the banana , but my least favorite is the strawberry .\n",
      "FR-> notre fruit préféré moins est la banane mais mon préféré moins est la fraise\n",
      "-\n",
      "EN   the peach is my favorite fruit , but the grapefruit is her favorite .\n",
      "FR-> la pêche est mon fruit préféré mais le pamplemousse est son favori\n",
      "-\n",
      "EN   france is pleasant during january , and it is never wonderful in october .\n",
      "FR-> la france est agréable en janvier et il est jamais merveilleux en octobre\n",
      "-\n",
      "EN   she likes that little blue car .\n",
      "FR-> elle aime cette petite voiture bleue\n",
      "-\n",
      "EN   new jersey is usually pleasant during march , and it is usually dry in winter .\n",
      "FR-> new jersey est généralement agréable en mars et il est généralement sec en hiver\n",
      "-\n",
      "EN   the grape is her least liked fruit , but the lemon is your least liked.\n",
      "FR-> le raisin est la moins aimé des fruits mais le citron est votre moins aimé\n",
      "-\n",
      "EN   the pear is our least favorite fruit , but the grape is her least favorite .\n",
      "FR-> la poire est notre fruit préféré moins mais le raisin est son moins préféré\n",
      "-\n",
      "EN   she wanted to go to new jersey last march .\n",
      "FR-> elle voulait aller au new jersey en mars dernier\n",
      "-\n",
      "EN   the united states is usually relaxing during march , but it is sometimes warm in october .\n",
      "FR-> les étatsunis est relaxant habituellement au mois de mars mais il est parfois chaud en octobre\n",
      "-\n",
      "EN   india is mild during may , but it is usually quiet in march .\n",
      "FR-> l inde est doux au mois de mai mais il est généralement calme en mars\n",
      "-\n",
      "EN   he dislikes peaches , pears , and limes .\n",
      "FR-> il naime les pêches les poires et citrons verts\n",
      "-\n",
      "EN   new jersey is never busy during march , but it is mild in fall .\n",
      "FR-> new jersey est jamais occupée en mars mais il est doux a l automne\n",
      "-\n",
      "EN   his favorite fruit is the peach , but our favorite is the mango .\n",
      "FR-> son fruit préféré est la pêche mais notre préféré est la mangue\n",
      "-\n",
      "EN   he was driving that shiny white car .\n",
      "FR-> il conduisait cette voiture blanche brillante\n",
      "-\n",
      "EN   new jersey is usually warm during may , but it is snowy in july .\n",
      "FR-> new jersey est habituellement chaud au mois de mai mais il est neigeux en juillet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fra_vocab = target_vectorization.get_vocabulary()\n",
    "fra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence_rnn(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization([decoded_sentence])\n",
    "        next_token_predictions = seq2seq_rnn.predict(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence], verbose=0)\n",
    "        sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
    "        sampled_token = fra_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence[8:-6]\n",
    "\n",
    "for i in range(20):\n",
    "    print(\"-\")\n",
    "    print(\"EN  \",input_sentence[i])\n",
    "    print(\"FR->\",decode_sequence_rnn(input_sentence[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<br></br>\n",
    "**You turn to play:** Enter a sentence.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR-> paris est généralement pluvieux pendant l été mais il est jamais merveilleux en hiver\n"
     ]
    }
   ],
   "source": [
    "your_sentence = \"paris   is usually rainy during summer , but france is never wonderful in winter\"\n",
    "print(\"FR->\",decode_sequence_rnn(your_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **3. Sequence-to-sequence learning with Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The Transformer decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `TransformerDecoder`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = mask\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Putting it all together: A Transformer for machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading of the trained Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras_nlp.layers import TransformerEncoder\n",
    "transformer = keras.models.load_model(\n",
    "    \"../data/transformer-fra-en-model.h5\",\n",
    "    custom_objects={\"PositionalEmbedding\": PositionalEmbedding, \"TransformerDecoder\": TransformerDecoder},\n",
    ")\n",
    "transformer.load_weights(\"../data/transformer-fra-en-model.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Translating new sentences with our Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "EN   india is beautiful during october , and it is quiet in fall .\n",
      "FR-> l inde est beau en octobre et il est calme a l automne\n",
      "-\n",
      "EN   india is pleasant during fall , but it is never beautiful in winter .\n",
      "FR-> l inde est agréable a lautomne mais il est beau jamais en hiver\n",
      "-\n",
      "EN   the united states is snowy during january , and it is never chilly in autumn .\n",
      "FR-> les étatsunis est la neige en janvier et il est jamais froid a l automne\n",
      "-\n",
      "EN   new jersey is usually beautiful during april , but it is dry in may .\n",
      "FR-> new jersey est généralement beau en avril mais il est sec en mai\n",
      "-\n",
      "EN   he dislikes bananas , grapes , and strawberries .\n",
      "FR-> il naime les bananes les raisins et les fraises\n",
      "-\n",
      "EN   our least favorite fruit is the banana , but my least favorite is the strawberry .\n",
      "FR-> notre fruit préféré moins est la banane mais mon préféré moins est la fraise\n",
      "-\n",
      "EN   the peach is my favorite fruit , but the grapefruit is her favorite .\n",
      "FR-> la pêche est mon fruit préféré mais le pamplemousse est son favori\n",
      "-\n",
      "EN   france is pleasant during january , and it is never wonderful in october .\n",
      "FR-> la france est agréable en janvier et il est jamais merveilleux en octobre\n",
      "-\n",
      "EN   she likes that little blue car .\n",
      "FR-> elle aime cette petite voiture bleue\n",
      "-\n",
      "EN   new jersey is usually pleasant during march , and it is usually dry in winter .\n",
      "FR-> new jersey est généralement agréable en mars et il est généralement sec en hiver\n",
      "-\n",
      "EN   the grape is her least liked fruit , but the lemon is your least liked.\n",
      "FR-> le raisin est la moins aimé des fruits mais le citron est votre moins aimé\n",
      "-\n",
      "EN   the pear is our least favorite fruit , but the grape is her least favorite .\n",
      "FR-> la poire est notre fruit préféré moins mais le raisin est son moins préféré\n",
      "-\n",
      "EN   she wanted to go to new jersey last march .\n",
      "FR-> elle voulait aller au new jersey en mars dernier\n",
      "-\n",
      "EN   the united states is usually relaxing during march , but it is sometimes warm in october .\n",
      "FR-> les étatsunis est relaxant habituellement au mois de mars mais il est parfois chaud en octobre\n",
      "-\n",
      "EN   india is mild during may , but it is usually quiet in march .\n",
      "FR-> l inde est doux au mois de mai mais il est généralement calme en mars\n",
      "-\n",
      "EN   he dislikes peaches , pears , and limes .\n",
      "FR-> il naime les pêches les poires et citrons verts\n",
      "-\n",
      "EN   new jersey is never busy during march , but it is mild in fall .\n",
      "FR-> new jersey est jamais occupée en mars mais il est doux a l automne\n",
      "-\n",
      "EN   his favorite fruit is the peach , but our favorite is the mango .\n",
      "FR-> son fruit préféré est la pêche mais notre préféré est la mangue\n",
      "-\n",
      "EN   he was driving that shiny white car .\n",
      "FR-> il conduisait cette voiture blanche brillante\n",
      "-\n",
      "EN   new jersey is usually warm during may , but it is snowy in july .\n",
      "FR-> new jersey est habituellement chaud au mois de mai mais il est neigeux en juillet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "fra_vocab = target_vectorization.get_vocabulary()\n",
    "fra_index_lookup = dict(zip(range(len(fra_vocab)), fra_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence_tranf(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = fra_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence[8:-6]\n",
    "\n",
    "for i in range(20):\n",
    "    print(\"-\")\n",
    "    print(\"EN  \",input_sentence[i])\n",
    "    print(\"FR->\",decode_sequence_tranf(input_sentence[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "<br></br>\n",
    "**You turn to play:** Enter a sentence.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR-> paris est généralement pluvieux en été mais il est jamais merveilleux en hiver\n"
     ]
    }
   ],
   "source": [
    "your_sentence = \"paris   is usually rainy during summer , but france is never wonderful in winter\"\n",
    "print(\"FR->\",decode_sequence_tranf(your_sentence))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11_part04_sequence-to-sequence-learning.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
